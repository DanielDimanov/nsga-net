{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NSGA-NOTE",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgmbuKYRr0AN",
        "colab_type": "code",
        "outputId": "3405bb03-04ab-4388-b2ef-484144466e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3xRup9GsBU2",
        "colab_type": "code",
        "outputId": "ad462e6d-fc25-4877-baa1-cb0e09206a9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "!git clone https://github.com/DanielDimanov/nsga-net.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nsga-net'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/31)   \u001b[K\rremote: Counting objects:   6% (2/31)   \u001b[K\rremote: Counting objects:   9% (3/31)   \u001b[K\rremote: Counting objects:  12% (4/31)   \u001b[K\rremote: Counting objects:  16% (5/31)   \u001b[K\rremote: Counting objects:  19% (6/31)   \u001b[K\rremote: Counting objects:  22% (7/31)   \u001b[K\rremote: Counting objects:  25% (8/31)   \u001b[K\rremote: Counting objects:  29% (9/31)   \u001b[K\rremote: Counting objects:  32% (10/31)   \u001b[K\rremote: Counting objects:  35% (11/31)   \u001b[K\rremote: Counting objects:  38% (12/31)   \u001b[K\rremote: Counting objects:  41% (13/31)   \u001b[K\rremote: Counting objects:  45% (14/31)   \u001b[K\rremote: Counting objects:  48% (15/31)   \u001b[K\rremote: Counting objects:  51% (16/31)   \u001b[K\rremote: Counting objects:  54% (17/31)   \u001b[K\rremote: Counting objects:  58% (18/31)   \u001b[K\rremote: Counting objects:  61% (19/31)   \u001b[K\rremote: Counting objects:  64% (20/31)   \u001b[K\rremote: Counting objects:  67% (21/31)   \u001b[K\rremote: Counting objects:  70% (22/31)   \u001b[K\rremote: Counting objects:  74% (23/31)   \u001b[K\rremote: Counting objects:  77% (24/31)   \u001b[K\rremote: Counting objects:  80% (25/31)   \u001b[K\rremote: Counting objects:  83% (26/31)   \u001b[K\rremote: Counting objects:  87% (27/31)   \u001b[K\rremote: Counting objects:  90% (28/31)   \u001b[K\rremote: Counting objects:  93% (29/31)   \u001b[K\rremote: Counting objects:  96% (30/31)   \u001b[K\rremote: Counting objects: 100% (31/31)   \u001b[K\rremote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 540 (delta 18), reused 15 (delta 7), pack-reused 509\u001b[K\n",
            "Receiving objects: 100% (540/540), 2.50 MiB | 6.88 MiB/s, done.\n",
            "Resolving deltas: 100% (255/255), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJFaz7nGsb2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd nsga-net/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Bi46W-vS5B",
        "colab_type": "code",
        "outputId": "301d82e0-363c-47be-a24b-e4e8af06f2cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGfPyCsLtFYC",
        "colab_type": "code",
        "outputId": "134da87c-fac9-4ced-f2c2-d4165e3d3e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "!pyt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: pyt: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8XGkvWcvAKC",
        "colab_type": "code",
        "outputId": "17870ac8-285f-4c59-e398-9d15543a0fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "!ls nsga-net/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "img  misc  models  README.md  search  validation  visualization\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-7EHqibvQhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/nsga-net/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riLg5cTbu4d0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import search.cifar10_search as my_cifar10\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv-eS6PlvwXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n",
        "CIFAR_STD = [0.24703233, 0.24348505, 0.26158768]\n",
        "\n",
        "# data agumentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "train_transform.transforms.append(transforms.Normalize(CIFAR_MEAN, CIFAR_STD))\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(CIFAR_MEAN, CIFAR_STD),\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_grp9s3mtQky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_root = './data'\n",
        "train_data = my_cifar10.CIFAR10(root=data_root, train=True, download=True, transform=train_transform)\n",
        "valid_data = my_cifar10.CIFAR10(root=data_root, train=False, download=True, transform=valid_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FlVubcHvcw0",
        "colab_type": "code",
        "outputId": "dc8e0a01-ae6f-4c87-fba7-8cc9f62da33d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "search.cifar10_search.CIFAR10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjV3XKycxKJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.utils.data as data\n",
        "import pandas as pd\n",
        "class WeaponDetection(data.Dataset):\n",
        "    def __init__(self, labels_file, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.landmarks_frame = pd.read_csv(labels_file,sep=\" \", header=None)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.landmarks_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.landmarks_frame.ix[idx, 0])\n",
        "        image = io.imread(img_name)\n",
        "        landmarks = self.landmarks_frame.ix[idx, 1:].as_matrix().astype('float')\n",
        "        landmarks = landmarks.reshape(-1, 2)\n",
        "        sample = {'image': image, 'landmarks': landmarks}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3aeCWRJyY5D",
        "colab_type": "code",
        "outputId": "f59ffb3e-6272-4061-c7d5-d58d3823fc93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "lblSFile=\"/content/gdrive/My Drive/datasetTrain/labelsFin.txt\"\n",
        "pd.read_csv(lblSFile,sep=\" \",header=None)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>riffle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pistol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>noThreat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>knife</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0\n",
              "0    riffle\n",
              "1    pistol\n",
              "2  noThreat\n",
              "3     knife"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7TMMbsWwul6",
        "colab_type": "code",
        "outputId": "0968404f-b676-4a9d-d4ae-7d8ce1cd5102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "!unzip /content/gdrive/My\\ Drive/MScProject/dataFinal.zip"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/My Drive/MScProject/dataFinal.zip\n",
            "replace dataFinal/train/riffle/riffle67.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace dataFinal/train/riffle/riffle209.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8vz6tC9wJk0",
        "colab_type": "code",
        "outputId": "0132cfc1-f825-4c25-bc48-31aef0c88698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import pathlib\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "folders ={\"train\":\"/content/dataFinal/train\", \"validation\":\"/content/dataFinal/validation\"}\n",
        "lblSFile=\"/content/gdrive/My Drive/datasetTrain/labelsFin.txt\"\n",
        "file = open(lblSFile, \"r\")\n",
        "imCLs=[]\n",
        "for imCL in file:\n",
        "  imCLs.append(str(imCL)[:-1])\n",
        "X_train,Y_train,X_val,Y_val=[],[],[],[]\n",
        "for step in ['train','validation']:\n",
        "    X,Y=[],[]\n",
        "    for cl in imCLs:\n",
        "        directory=''+folders[step]+\"/\"+str(cl)\n",
        "        print(\"Getting images from:\"+directory)\n",
        "        size=512,512\n",
        "        print(\"Processing class \"+ str(cl))\n",
        "        for filename in os.listdir(directory):\n",
        "            if(filename.startswith('.')):\n",
        "                continue\n",
        "            else:\n",
        "                img = image.load_img(directory+'/'+filename,target_size=(128,128,3),grayscale=False)\n",
        "                img = image.img_to_array(img)\n",
        "                img = img/255\n",
        "                X.append(img)\n",
        "                lbl=str(cl)\n",
        "                Y.append(imCLs.index(lbl))\n",
        "    if(step=='train'):\n",
        "        X_train = np.array(X)\n",
        "        Y_train = np.array(Y)\n",
        "    if(step=='validation'):\n",
        "        X_val = np.array(X)\n",
        "        Y_val = np.array(Y)\n",
        "    del X\n",
        "    del Y"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Getting images from:/content/dataFinal/train/riffle\n",
            "Processing class riffle\n",
            "Getting images from:/content/dataFinal/train/pistol\n",
            "Processing class pistol\n",
            "Getting images from:/content/dataFinal/train/noThreat\n",
            "Processing class noThreat\n",
            "Getting images from:/content/dataFinal/train/knife\n",
            "Processing class knife\n",
            "Getting images from:/content/dataFinal/validation/riffle\n",
            "Processing class riffle\n",
            "Getting images from:/content/dataFinal/validation/pistol\n",
            "Processing class pistol\n",
            "Getting images from:/content/dataFinal/validation/noThreat\n",
            "Processing class noThreat\n",
            "Getting images from:/content/dataFinal/validation/knife\n",
            "Processing class knife\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRCzbILc88Vq",
        "colab_type": "code",
        "outputId": "67a00f7a-f75f-4cbe-d4cd-c99379da6863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_swap = np.swapaxes(X_train,-1,1)\n",
        "X_val_swap = np.swapaxes(X_val,-1,1)\n",
        "X_train_swap.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2140, 3, 128, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHDvBYnr3uUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Uk61x-V1hBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = data.TensorDataset(torch.from_numpy(X_train_swap),torch.from_numpy(Y_train))\n",
        "val_dataset = data.TensorDataset(torch.from_numpy(X_val_swap),torch.from_numpy(Y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_BjpLgQ08hJ",
        "colab_type": "code",
        "outputId": "3cffc46e-d1b7-4b88-f490-13c641a707dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.mean(X_train,axis=(0,1,2))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.4785047 , 0.45566642, 0.42557254], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCosLoav13qc",
        "colab_type": "code",
        "outputId": "855b931c-c893-4471-c204-ecf9321bf9df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.std(X_train,axis=(0,1,2))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.319471  , 0.31107742, 0.3122497 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VlmXPOa5Xpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import logging\n",
        "import argparse\n",
        "import torch.nn as nn\n",
        "import torch.utils\n",
        "# import torchvision.datasets as dset\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from models.macro_models import EvoNetwork\n",
        "from models.micro_models import NetworkCIFAR as Network\n",
        "\n",
        "import search.cifar10_search as my_cifar10\n",
        "\n",
        "import time\n",
        "from misc import utils\n",
        "from search import micro_encoding\n",
        "from search import macro_encoding\n",
        "from misc.flops_counter import add_flops_counting_methods\n",
        "\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "\n",
        "def main(genome, epochs, search_space='micro',\n",
        "         save='Design_1', expr_root='search', seed=0, gpu=0, init_channels=24,\n",
        "         layers=11, auxiliary=False, cutout=False, drop_path_prob=0.0):\n",
        "\n",
        "    # ---- train logger ----------------- #\n",
        "    save_pth = os.path.join(expr_root, '{}'.format(save))\n",
        "    utils.create_exp_dir(save_pth)\n",
        "    log_format = '%(asctime)s %(message)s'\n",
        "    logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
        "                        format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
        "    # fh = logging.FileHandler(os.path.join(save_pth, 'log.txt'))\n",
        "    # fh.setFormatter(logging.Formatter(log_format))\n",
        "    # logging.getLogger().addHandler(fh)\n",
        "\n",
        "    # ---- parameter values setting ----- #\n",
        "    NUM_CLASSES = 4\n",
        "    CIFAR_CLASSES = NUM_CLASSES\n",
        "    DATA_SHAPE = (128, 128)\n",
        "    INPUT_CHANNELS = 3\n",
        "    learning_rate = 0.025\n",
        "    momentum = 0.9\n",
        "    weight_decay = 3e-4\n",
        "    data_root = '../data'\n",
        "    batch_size = 32\n",
        "    cutout_length = 16\n",
        "    auxiliary_weight = 0.4\n",
        "    grad_clip = 5\n",
        "    report_freq = 50\n",
        "    train_params = {\n",
        "        'auxiliary': auxiliary,\n",
        "        'auxiliary_weight': auxiliary_weight,\n",
        "        'grad_clip': grad_clip,\n",
        "        'report_freq': report_freq,\n",
        "    }\n",
        "\n",
        "    if search_space == 'micro':\n",
        "        genotype = micro_encoding.decode(genome)\n",
        "        model = Network(init_channels, CIFAR_CLASSES, layers, auxiliary, genotype)\n",
        "    elif search_space == 'macro':\n",
        "        genotype = macro_encoding.decode(genome)\n",
        "        channels = [(INPUT_CHANNELS, init_channels),\n",
        "                    (init_channels, 2*init_channels),\n",
        "                    (2*init_channels, 4*init_channels)]\n",
        "        model = EvoNetwork(genotype, channels, CIFAR_CLASSES,DATA_SHAPE, decoder='residual')\n",
        "    else:\n",
        "        raise NameError('Unknown search space type')\n",
        "\n",
        "    # logging.info(\"Genome = %s\", genome)\n",
        "    logging.info(\"Architecture = %s\", genotype)\n",
        "\n",
        "    torch.cuda.set_device(gpu)\n",
        "    cudnn.benchmark = True\n",
        "    torch.manual_seed(seed)\n",
        "    cudnn.enabled = True\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    n_params = (np.sum(np.prod(v.size()) for v in filter(lambda p: p.requires_grad, model.parameters())) / 1e6)\n",
        "    model = model.to(device)\n",
        "\n",
        "    logging.info(\"param size = %fMB\", n_params)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    criterion = criterion.cuda()\n",
        "\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optimizer = torch.optim.SGD(\n",
        "        parameters,\n",
        "        learning_rate,\n",
        "        momentum=momentum,\n",
        "        weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    #TO DO: change\n",
        "    CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n",
        "    DATASET_MEAN = [0.4785047 , 0.45649716, 0.42604172]\n",
        "    CIFAR_MEAN = DATASET_MEAN\n",
        "    DATASET_STD = [0.31962952, 0.3112294 , 0.31206125]\n",
        "    CIFAR_STD = [0.24703233, 0.24348505, 0.26158768]\n",
        "    CIFAR_STD = DATASET_STD\n",
        "#     # data agumentation\n",
        "#     train_transform = transforms.Compose([\n",
        "#         transforms.RandomCrop(32, padding=4),\n",
        "#         transforms.RandomHorizontalFlip(),\n",
        "#         transforms.ToTensor()\n",
        "#     ])\n",
        "\n",
        "#     if cutout:\n",
        "#         train_transform.transforms.append(utils.Cutout(cutout_length))\n",
        "\n",
        "#     train_transform.transforms.append(transforms.Normalize(CIFAR_MEAN, CIFAR_STD))\n",
        "\n",
        "#     valid_transform = transforms.Compose([\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize(CIFAR_MEAN, CIFAR_STD),\n",
        "#     ])\n",
        "\n",
        "#     train_data = my_cifar10.CIFAR10(root=data_root, train=True, download=True, transform=train_transform)\n",
        "#     valid_data = my_cifar10.CIFAR10(root=data_root, train=False, download=True, transform=valid_transform)\n",
        "\n",
        "#     # num_train = len(train_data)\n",
        "#     # indices = list(range(num_train))\n",
        "#     # split = int(np.floor(train_portion * num_train))\n",
        "    train_data = train_dataset\n",
        "    valid_data = val_dataset\n",
        "    train_queue = torch.utils.data.DataLoader(\n",
        "        train_data, batch_size=batch_size,\n",
        "        # sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[:split]),\n",
        "        pin_memory=True, num_workers=4)\n",
        "\n",
        "    valid_queue = torch.utils.data.DataLoader(\n",
        "        valid_data, batch_size=batch_size,\n",
        "        # sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[split:num_train]),\n",
        "        pin_memory=True, num_workers=4)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, int(epochs))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        scheduler.step()\n",
        "        logging.info('epoch %d lr %e', epoch, scheduler.get_lr()[0])\n",
        "        model.droprate = drop_path_prob * epoch / epochs\n",
        "\n",
        "        train_acc, train_obj = train(train_queue, model, criterion, optimizer, train_params)\n",
        "        logging.info('train_acc %f', train_acc)\n",
        "\n",
        "    valid_acc, valid_obj = infer(valid_queue, model, criterion)\n",
        "    logging.info('valid_acc %f', valid_acc)\n",
        "\n",
        "    # calculate for flops\n",
        "    model = add_flops_counting_methods(model)\n",
        "    model.eval()\n",
        "    model.start_flops_count()\n",
        "    random_data = torch.randn(1, INPUT_CHANNELS, *DATA_SHAPE)\n",
        "    model(torch.autograd.Variable(random_data).to(device))\n",
        "    n_flops = np.round(model.compute_average_flops_cost() / 1e6, 4)\n",
        "    logging.info('flops = %f', n_flops)\n",
        "\n",
        "    # save to file\n",
        "    # os.remove(os.path.join(save_pth, 'log.txt'))\n",
        "    with open(os.path.join(save_pth, 'log.txt'), \"w\") as file:\n",
        "        file.write(\"Genome = {}\\n\".format(genome))\n",
        "        file.write(\"Architecture = {}\\n\".format(genotype))\n",
        "        file.write(\"param size = {}MB\\n\".format(n_params))\n",
        "        file.write(\"flops = {}MB\\n\".format(n_flops))\n",
        "        file.write(\"valid_acc = {}\\n\".format(valid_acc))\n",
        "\n",
        "    # logging.info(\"Architecture = %s\", genotype))\n",
        "\n",
        "    return {\n",
        "        'valid_acc': valid_acc,\n",
        "        'params': n_params,\n",
        "        'flops': n_flops,\n",
        "    }\n",
        "\n",
        "\n",
        "# def train(train_queue, model, criterion, optimizer, params):\n",
        "#     objs = utils.AvgrageMeter()\n",
        "#     top1 = utils.AvgrageMeter()\n",
        "#     top5 = utils.AvgrageMeter()\n",
        "#     model.train()\n",
        "#\n",
        "#     for step, (input, target) in enumerate(train_queue):\n",
        "#         input = Variable(input).cuda()\n",
        "#         target = Variable(target).cuda(async=True)\n",
        "#\n",
        "#         optimizer.zero_grad()\n",
        "#         if params['auxiliary']:\n",
        "#             logits, logits_aux = model(input)\n",
        "#         else:\n",
        "#             logits, _ = model(input)\n",
        "#\n",
        "#         loss = criterion(logits, target)\n",
        "#         if params['auxiliary']:\n",
        "#             loss_aux = criterion(logits_aux, target)\n",
        "#             loss += params['auxiliary_weight'] * loss_aux\n",
        "#         loss.backward()\n",
        "#         nn.utils.clip_grad_norm(model.parameters(), params['grad_clip'])\n",
        "#         optimizer.step()\n",
        "#\n",
        "#         prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n",
        "#         n = input.size(0)\n",
        "#         objs.update(loss.data[0], n)\n",
        "#         top1.update(prec1.data[0], n)\n",
        "#         top5.update(prec5.data[0], n)\n",
        "#\n",
        "#         # if step % params['report_freq'] == 0:\n",
        "#         #     logging.info('train %03d %e %f %f', step, objs.avg, top1.avg, top5.avg)\n",
        "#\n",
        "#     return top1.avg, objs.avg\n",
        "\n",
        "# Training\n",
        "def train(train_queue, net, criterion, optimizer, params):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for step, (inputs, targets) in enumerate(train_queue):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs, outputs_aux = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        if params['auxiliary']:\n",
        "            loss_aux = criterion(outputs_aux, targets)\n",
        "            loss += params['auxiliary_weight'] * loss_aux\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), params['grad_clip'])\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    #     if step % args.report_freq == 0:\n",
        "    #         logging.info('train %03d %e %f', step, train_loss/total, 100.*correct/total)\n",
        "    #\n",
        "    # logging.info('train acc %f', 100. * correct / total)\n",
        "\n",
        "    return 100.*correct/total, train_loss/total\n",
        "\n",
        "\n",
        "# def infer(valid_queue, model, criterion):\n",
        "#     objs = utils.AvgrageMeter()\n",
        "#     top1 = utils.AvgrageMeter()\n",
        "#     top5 = utils.AvgrageMeter()\n",
        "#     model.eval()\n",
        "#\n",
        "#     for step, (input, target) in enumerate(valid_queue):\n",
        "#         input = Variable(input, volatile=True).cuda()\n",
        "#         target = Variable(target, volatile=True).cuda(async=True)\n",
        "#\n",
        "#         logits, _ = model(input)\n",
        "#\n",
        "#         loss = criterion(logits, target)\n",
        "#\n",
        "#         prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n",
        "#         n = input.size(0)\n",
        "#         objs.update(loss.data[0], n)\n",
        "#         top1.update(prec1.data[0], n)\n",
        "#         top5.update(prec5.data[0], n)\n",
        "#\n",
        "#         # if step % params['report_freq'] == 0:\n",
        "#         #     logging.info('valid %03d %e %f %f', step, objs.avg, top1.avg, top5.avg)\n",
        "#\n",
        "#     return top1.avg, objs.avg\n",
        "\n",
        "\n",
        "def infer(valid_queue, net, criterion):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step, (inputs, targets) in enumerate(valid_queue):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs, _ = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # if step % args.report_freq == 0:\n",
        "            #     logging.info('valid %03d %e %f', step, test_loss/total, 100.*correct/total)\n",
        "\n",
        "    acc = 100.*correct/total\n",
        "    # logging.info('valid acc %f', 100. * correct / total)\n",
        "\n",
        "    return acc, test_loss/total\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVdV9Na47uCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir searchv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAQRnjeI7L5S",
        "colab_type": "code",
        "outputId": "a89221e3-22bc-49d6-cbf4-fbdcbb620ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        }
      },
      "source": [
        "    DARTS_V2 = [[[[3, 0], [3, 1]], [[3, 0], [3, 1]], [[3, 1], [2, 0]], [[2, 0], [5, 2]]],\n",
        "               [[[0, 0], [0, 1]], [[2, 2], [0, 1]], [[0, 0], [2, 2]], [[2, 2], [0, 1]]]]\n",
        "    start = time.time()\n",
        "    print(main(genome=DARTS_V2, epochs=20, save='BATCH_TEST', seed=1, init_channels=16,\n",
        "               auxiliary=False, cutout=False, drop_path_prob=0.0))\n",
        "    print('Time elapsed = {} mins'.format((time.time() - start)/60))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment dir : search/BATCH_TEST\n",
            "48 48 16\n",
            "48 48 16\n",
            "48 48 16\n",
            "48 48 32\n",
            "48 96 32\n",
            "96 96 32\n",
            "96 96 32\n",
            "96 96 64\n",
            "96 192 64\n",
            "192 192 64\n",
            "192 192 64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:83: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-0079b1411b92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m print(main(genome=DARTS_V2, epochs=20, save='BATCH_TEST', seed=1, init_channels=16,\n\u001b[0;32m----> 5\u001b[0;31m            auxiliary=False, cutout=False, drop_path_prob=0.0))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time elapsed = {} mins'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-bbb9cf46d59c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(genome, epochs, search_space, save, expr_root, seed, gpu, init_channels, layers, auxiliary, cutout, drop_path_prob)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdroprate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop_path_prob\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_acc %f'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-bbb9cf46d59c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_queue, net, criterion, optimizer, params)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'grad_clip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mtotal_norm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNqE83Ks7Mc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Wz_8q49mQd",
        "colab_type": "code",
        "outputId": "366f68af-ca61-443f-9694-309a4fe0457e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Aug  6 13:40:01 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    57W / 149W |    668MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESdYLxr_9twA",
        "colab_type": "code",
        "outputId": "406f6cb5-54d1-42e1-ea8b-568072138e7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "source": [
        "!sudo nvidia-smi --gpu-reset -i 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Failed to initialize NVML: Driver/library version mismatch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJsHel1V93GW",
        "colab_type": "code",
        "outputId": "5f287a26-9254-43b8-c52c-6f8917dda853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/ianwhale/nsga-net.git nsga-net-official"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nsga-net-official'...\n",
            "remote: Enumerating objects: 509, done.\u001b[K\n",
            "remote: Total 509 (delta 0), reused 0 (delta 0), pack-reused 509\u001b[K\n",
            "Receiving objects: 100% (509/509), 2.49 MiB | 1.95 MiB/s, done.\n",
            "Resolving deltas: 100% (237/237), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZUxlBlhGclO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-27ANZtPGcdk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf4d4f8R_igH",
        "colab_type": "code",
        "outputId": "aaf35903-2acc-404f-aa20-e568d7c947c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "!python search/evolution_search.py --search_space macro --init_channels 32 --n_gens 30"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"search/evolution_search.py\", line 9, in <module>\n",
            "    from misc import utils\n",
            "ModuleNotFoundError: No module named 'misc'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKTAJkUQ_xly",
        "colab_type": "code",
        "outputId": "167f09e6-2765-4978-e6ca-70bda11ba42a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "__init__.py file\n",
        "\n",
        "import os\n",
        "import sys\n",
        "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"validation/test.py\", line 20, in <module>\n",
            "    from misc import utils\n",
            "ModuleNotFoundError: No module named 'misc'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE1Qm1xsAJe7",
        "colab_type": "code",
        "outputId": "d4d0833c-e5e7-45be-c301-4247e0cb7ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "!cat  __init__.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "import os\n",
            "import sys\n",
            "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iotYT-BPFifS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"__init__.py\",\"w\") as f:\n",
        "  f.write(\"import os\\n\")\n",
        "  f.write(\"import sys\\n\")\n",
        "  f.write(\"sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDQasuJqDYqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!touch ../gdrive/My\\ Drive/__init__.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpvJwe7BD7Hu",
        "colab_type": "code",
        "outputId": "06408e1c-1f16-44d3-ba83-9ab77904f061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!ls ../gdrive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'2017-05-15 10-55 page 1.pdf'\n",
            " amoeba.json\n",
            "'Applications of Nuclear Physics in Medicine (1) (1).gslides'\n",
            "'Applications of Nuclear Physics in Medicine (1) (2).gslides'\n",
            "'Applications of Nuclear Physics in Medicine (1).gslides'\n",
            " Article.gdoc\n",
            "'article shit.docx'\n",
            " Black_sea_coast.pdf\n",
            " build_image_data.py\n",
            " build_image_dataTen.py\n",
            " Bulgarian_Diploma_Calculator.xls\n",
            "'Burp Suite Professional v1.5.01-1.rar'\n",
            "'Colab Notebooks'\n",
            " collab_data.gsheet\n",
            "'Copy of UVH website ER'\n",
            "'Customer Feedback.gform'\n",
            " Cv\n",
            "'Daniel Dimanov.doc'\n",
            "'Daniel Dimanov.doc.gdoc'\n",
            "'Daniel DimanovPersonal Statement Edited.doc'\n",
            " datasetTrain\n",
            " debelqnov.doc\n",
            " Doc1.docx\n",
            " drawable\n",
            " dyasiudij.gdraw\n",
            "'Final Projectium.gdoc'\n",
            " GeneticCNN_CIFAR10_AUGM.rar\n",
            "'Geo East Europe.gdoc'\n",
            "'gledam strashno.zip'\n",
            " IMG_0390.MOV\n",
            "\"Important Interview q's.docx\"\n",
            " Installatron\n",
            " jpeg_to_tf_record_Danv2.py\n",
            " jpeg_to_tf_record.py\n",
            " KD\n",
            " Lease_Agreement_Bright_Buildings_Rutronik_anex_NB.docx\n",
            " Mama\n",
            "'Map Projectum.pdf'\n",
            "'Math Project.gform'\n",
            "'Math Project (Responses).gsheet'\n",
            " _MG_0676.JPG\n",
            " MScProject\n",
            "'MSc Project'\n",
            "'My Saved Places.gmap'\n",
            " Netwalk\n",
            "'New pics for Netwalk'\n",
            " Notes.gdoc\n",
            "'Nuclear Medicine.gslides'\n",
            "'Operation Barbarossa.gmap'\n",
            "'pr 2.gdraw'\n",
            "'Predlogenie 4 August 2014.doc'\n",
            " Predlogenie_4_August_2014_English.doc\n",
            "'Project(in development).doc'\n",
            "'Project(in development).doc.gdoc'\n",
            " Proposal_and_characteristics_of_property_located_near_the_town_Haskovo.docx\n",
            "'Public health.docx'\n",
            " Reasons.gdoc\n",
            " rest-api\n",
            " rest-api.zip\n",
            "'Shano Projects'\n",
            " Skleppers\n",
            "'star(fin).psd'\n",
            " star.psd\n",
            " Statistics_Project_Daniel_Dimanov_12_3.gslides\n",
            "'Table TULoB.gdoc'\n",
            "'The Aikon project was a success in my opinion.docx'\n",
            "'Translated copy of Test Plan Monitorin App.gdoc'\n",
            "'Untitled document.gdoc'\n",
            "'UV light.gslides'\n",
            "'UV light handout.gdoc'\n",
            " viza_1page.jpg\n",
            " VMware\n",
            " WebProgAss\n",
            " Worksheetium.gdoc\n",
            " _latex_29.12.2014.odt\n",
            " _latex_29.12.2014.odt.gdoc\n",
            "'     .gdoc'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd_NOBcPAKel",
        "colab_type": "code",
        "outputId": "96956931-0502-471b-b0d5-47388b8b8195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "!pip install pymoo"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymoo\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/bd/bf0dfec7d9692a8cc65b05d7dff98c2dd9e8a53f952d84d8bbe35f209f50/pymoo-0.3.0.tar.gz (531kB)\n",
            "\u001b[K     || 532kB 5.3MB/s \n",
            "\u001b[?25hCollecting pymop==0.2.4 (from pymoo)\n",
            "  Downloading https://files.pythonhosted.org/packages/69/3e/110daf255c660b1b3efe9689a0f5340504892778172c4fa330c96d516c24/pymop-0.2.4-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from pymoo) (1.16.4)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.6/dist-packages (from pymoo) (1.3.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.6/dist-packages (from pymoo) (3.0.3)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.6/dist-packages (from pymop==0.2.4->pymoo) (1.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3->pymoo) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3->pymoo) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3->pymoo) (2.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3->pymoo) (2.5.3)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from autograd->pymop==0.2.4->pymoo) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3->pymoo) (41.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=3->pymoo) (1.12.0)\n",
            "Building wheels for collected packages: pymoo\n",
            "  Building wheel for pymoo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymoo: filename=pymoo-0.3.0-cp36-cp36m-linux_x86_64.whl size=1713415 sha256=136524aac47c1d204b0ce7da5b395861540921080e30fcd773190a2c16496df3\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/ca/e9/4217337eac3d9894873ff103bfe69026427a6fe205af349952\n",
            "Successfully built pymoo\n",
            "Installing collected packages: pymop, pymoo\n",
            "Successfully installed pymoo-0.3.0 pymop-0.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVZ0bGM7AaW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export PYTHONPATH=\"$PYTHONPATH:/content/nsga-net-official/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BydUpEcSAjEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/nsga-net-official/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2KL0DsbA3Cs",
        "colab_type": "code",
        "outputId": "d1d28779-9301-491a-ab67-c51291fced47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sys.path[9]=sys.path[10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/env/python',\n",
              " '/usr/lib/python36.zip',\n",
              " '/usr/lib/python3.6',\n",
              " '/usr/lib/python3.6/lib-dynload',\n",
              " '/usr/local/lib/python3.6/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/content/nsga-net/',\n",
              " '/content/nsga-net-official/']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcIsHcF_A6F0",
        "colab_type": "code",
        "outputId": "34459f4f-791f-438b-bfd5-0ad150816e44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "sys.path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/env/python',\n",
              " '/usr/lib/python36.zip',\n",
              " '/usr/lib/python3.6',\n",
              " '/usr/lib/python3.6/lib-dynload',\n",
              " '/usr/local/lib/python3.6/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/content/nsga-net-official/']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afoYjIFDBKO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.path.remove('/content/nsga-net/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ3H4GjMBNUL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "160608bf-7a8b-4570-90d4-185ab5eb43e1"
      },
      "source": [
        "!git clone https://github.com/DanielDimanov/nsga-net.git"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)   \u001b[K\rremote: Counting objects:  40% (2/5)   \u001b[K\rremote: Counting objects:  60% (3/5)   \u001b[K\rremote: Counting objects:  80% (4/5)   \u001b[K\rremote: Counting objects: 100% (5/5)   \u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects:  20% (1/5)   \u001b[K\rremote: Compressing objects:  40% (2/5)   \u001b[K\rremote: Compressing objects:  60% (3/5)   \u001b[K\rremote: Compressing objects:  80% (4/5)   \u001b[K\rremote: Compressing objects: 100% (5/5)   \u001b[K\rremote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  20% (1/5)   \rUnpacking objects:  40% (2/5)   \rUnpacking objects:  60% (3/5)   \rUnpacking objects:  80% (4/5)   \rUnpacking objects: 100% (5/5)   \rUnpacking objects: 100% (5/5), done.\n",
            "From https://github.com/DanielDimanov/nsga-net\n",
            " * branch            HEAD       -> FETCH_HEAD\n",
            "Updating 55a831e..e95ee66\n",
            "Fast-forward\n",
            " search/evolution_search.py | 65 \u001b[32m+++++++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m-\u001b[m\n",
            " search/train_search.py     |  2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 65 insertions(+), 2 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShuGhY86It_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06eb0166-22dc-4dd6-98b8-20c8f6a4dd07"
      },
      "source": [
        "!python nsga-net/search/evolution_search.py --save NSGATESTv1 --search_space micro --init_channels 16 --layers 8 --epochs 3 --n_offspring 20 --n_gens 30"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment dir : search-NSGATESTv1-micro-20190808-000917\n",
            "Using TensorFlow backend.\n",
            "Getting images from:/content/dataFinal/train/riffle\n",
            "Processing class riffle\n",
            "Getting images from:/content/dataFinal/train/pistol\n",
            "Processing class pistol\n",
            "Getting images from:/content/dataFinal/train/noThreat\n",
            "Processing class noThreat\n",
            "Getting images from:/content/dataFinal/train/knife\n",
            "Processing class knife\n",
            "Getting images from:/content/dataFinal/validation/riffle\n",
            "Processing class riffle\n",
            "Getting images from:/content/dataFinal/validation/pistol\n",
            "Processing class pistol\n",
            "Getting images from:/content/dataFinal/validation/noThreat\n",
            "Processing class noThreat\n",
            "Getting images from:/content/dataFinal/validation/knife\n",
            "Processing class knife\n",
            "08/08 12:09:29 AM args = Namespace(epochs=3, init_channels=16, labels_file_path='/content/gdrive/My Drive/datasetTrain/labelsFin.txt', layers=8, n_blocks=5, n_cells=2, n_gens=30, n_nodes=4, n_offspring=20, n_ops=9, pop_size=40, save='search-NSGATESTv1-micro-20190808-000917', search_space='micro', seed=0, train_data_directory='/content/dataFinal/train', validation_data_directory='/content/dataFinal/validation')\n",
            "\n",
            "\n",
            "08/08 12:09:29 AM Network id = 1\n",
            "Experiment dir : search-NSGATESTv1-micro-20190808-000917/arch_1\n",
            "48 48 16\n",
            "48 48 16\n",
            "48 48 32\n",
            "48 96 32\n",
            "96 96 32\n",
            "96 96 64\n",
            "96 192 64\n",
            "192 192 64\n",
            "08/08 12:09:29 AM Architecture = Genotype(normal=[('sep_conv_7x7', 0), ('dil_conv_5x5', 1), ('sep_conv_7x7', 0), ('sep_conv_7x7', 0), ('avg_pool_3x3', 0), ('avg_pool_3x3', 0), ('sep_conv_5x5', 1), ('dil_conv_3x3', 2), ('dil_conv_5x5', 1), ('avg_pool_3x3', 4)], normal_concat=[3, 5, 6], reduce=[('sep_conv_7x7', 0), ('dil_conv_5x5', 1), ('avg_pool_3x3', 0), ('max_pool_3x3', 0), ('dil_conv_3x3', 3), ('avg_pool_3x3', 2), ('max_pool_3x3', 2), ('dil_conv_5x5', 2), ('sep_conv_7x7', 3), ('avg_pool_3x3', 2)], reduce_concat=[4, 5, 6])\n",
            "08/08 12:09:31 AM param size = 0.350772MB\n",
            "08/08 12:09:31 AM epoch 0 lr 1.406250e-02\n",
            "08/08 12:11:56 AM train_acc 88.738318\n",
            "08/08 12:11:56 AM epoch 1 lr 2.083333e-03\n",
            "08/08 12:14:20 AM train_acc 82.757009\n",
            "08/08 12:14:20 AM epoch 2 lr 0.000000e+00\n",
            "08/08 12:16:45 AM train_acc 25.000000\n",
            "08/08 12:16:47 AM valid_acc 25.000000\n",
            "08/08 12:16:47 AM flops = 1073.283800\n",
            "\n",
            "\n",
            "08/08 12:16:47 AM Network id = 2\n",
            "Experiment dir : search-NSGATESTv1-micro-20190808-000917/arch_2\n",
            "48 48 16\n",
            "48 48 16\n",
            "48 48 32\n",
            "48 64 32\n",
            "64 96 32\n",
            "96 96 64\n",
            "96 128 64\n",
            "128 192 64\n",
            "08/08 12:16:47 AM Architecture = Genotype(normal=[('sep_conv_3x3', 0), ('dil_conv_5x5', 1), ('avg_pool_3x3', 2), ('dil_conv_5x5', 2), ('sep_conv_7x7', 1), ('sep_conv_3x3', 2), ('max_pool_3x3', 1), ('dil_conv_3x3', 1), ('sep_conv_7x7', 2), ('avg_pool_3x3', 4)], normal_concat=[3, 5, 6], reduce=[('avg_pool_3x3', 1), ('dil_conv_3x3', 1), ('avg_pool_3x3', 2), ('dil_conv_3x3', 0), ('dil_conv_3x3', 3), ('skip_connect', 0), ('sep_conv_5x5', 0), ('sep_conv_3x3', 0), ('dil_conv_3x3', 4), ('sep_conv_3x3', 3)], reduce_concat=[5, 6])\n",
            "08/08 12:16:47 AM param size = 0.323924MB\n",
            "08/08 12:16:47 AM epoch 0 lr 1.406250e-02\n",
            "08/08 12:18:53 AM train_acc 91.869159\n",
            "08/08 12:18:53 AM epoch 1 lr 2.083333e-03\n",
            "08/08 12:20:59 AM train_acc 82.803738\n",
            "08/08 12:20:59 AM epoch 2 lr 0.000000e+00\n",
            "08/08 12:23:07 AM train_acc 25.000000\n",
            "08/08 12:23:08 AM valid_acc 25.000000\n",
            "08/08 12:23:08 AM flops = 963.707600\n",
            "\n",
            "\n",
            "08/08 12:23:08 AM Network id = 3\n",
            "Experiment dir : search-NSGATESTv1-micro-20190808-000917/arch_3\n",
            "48 48 16\n",
            "48 32 16\n",
            "32 32 32\n",
            "32 64 32\n",
            "64 64 32\n",
            "64 64 64\n",
            "64 128 64\n",
            "128 128 64\n",
            "08/08 12:23:08 AM Architecture = Genotype(normal=[('sep_conv_7x7', 0), ('dil_conv_3x3', 1), ('sep_conv_3x3', 1), ('dil_conv_3x3', 0), ('sep_conv_5x5', 1), ('conv_7x1_1x7', 3), ('max_pool_3x3', 4), ('dil_conv_5x5', 2), ('sep_conv_7x7', 3), ('skip_connect', 2)], normal_concat=[5, 6], reduce=[('sep_conv_7x7', 1), ('sep_conv_7x7', 0), ('dil_conv_5x5', 0), ('sep_conv_5x5', 0), ('skip_connect', 3), ('dil_conv_5x5', 1), ('conv_7x1_1x7', 4), ('sep_conv_3x3', 1), ('sep_conv_5x5', 5), ('sep_conv_7x7', 0)], reduce_concat=[2, 6])\n",
            "08/08 12:23:08 AM param size = 0.585620MB\n",
            "08/08 12:23:08 AM epoch 0 lr 1.406250e-02\n",
            "08/08 12:25:41 AM train_acc 90.981308\n",
            "08/08 12:25:41 AM epoch 1 lr 2.083333e-03\n",
            "08/08 12:28:12 AM train_acc 79.439252\n",
            "08/08 12:28:12 AM epoch 2 lr 0.000000e+00\n",
            "08/08 12:30:44 AM train_acc 25.000000\n",
            "08/08 12:30:46 AM valid_acc 25.000000\n",
            "08/08 12:30:46 AM flops = 1491.599900\n",
            "\n",
            "\n",
            "08/08 12:30:46 AM Network id = 4\n",
            "Experiment dir : search-NSGATESTv1-micro-20190808-000917/arch_4\n",
            "48 48 16\n",
            "48 32 16\n",
            "32 32 32\n",
            "32 96 32\n",
            "96 64 32\n",
            "64 64 64\n",
            "64 192 64\n",
            "192 128 64\n",
            "08/08 12:30:46 AM Architecture = Genotype(normal=[('conv_7x1_1x7', 0), ('dil_conv_3x3', 1), ('max_pool_3x3', 0), ('max_pool_3x3', 2), ('avg_pool_3x3', 3), ('max_pool_3x3', 3), ('skip_connect', 1), ('dil_conv_5x5', 3), ('avg_pool_3x3', 3), ('sep_conv_5x5', 4)], normal_concat=[5, 6], reduce=[('dil_conv_3x3', 0), ('sep_conv_5x5', 0), ('sep_conv_5x5', 1), ('avg_pool_3x3', 0), ('avg_pool_3x3', 0), ('sep_conv_7x7', 3), ('sep_conv_5x5', 0), ('avg_pool_3x3', 2), ('avg_pool_3x3', 0), ('skip_connect', 2)], reduce_concat=[4, 5, 6])\n",
            "08/08 12:30:46 AM param size = 0.349396MB\n",
            "08/08 12:30:46 AM epoch 0 lr 1.406250e-02\n",
            "08/08 12:32:10 AM train_acc 91.869159\n",
            "08/08 12:32:10 AM epoch 1 lr 2.083333e-03\n",
            "08/08 12:33:34 AM train_acc 81.775701\n",
            "08/08 12:33:34 AM epoch 2 lr 0.000000e+00\n",
            "08/08 12:34:59 AM train_acc 25.000000\n",
            "08/08 12:35:00 AM valid_acc 25.000000\n",
            "08/08 12:35:00 AM flops = 909.967900\n",
            "\n",
            "\n",
            "08/08 12:35:00 AM Network id = 5\n",
            "Experiment dir : search-NSGATESTv1-micro-20190808-000917/arch_5\n",
            "48 48 16\n",
            "48 48 16\n",
            "48 48 32\n",
            "48 32 32\n",
            "32 96 32\n",
            "96 96 64\n",
            "96 64 64\n",
            "64 192 64\n",
            "08/08 12:35:00 AM Architecture = Genotype(normal=[('skip_connect', 0), ('conv_7x1_1x7', 1), ('sep_conv_3x3', 1), ('dil_conv_5x5', 1), ('avg_pool_3x3', 2), ('sep_conv_7x7', 1), ('dil_conv_3x3', 1), ('sep_conv_5x5', 3), ('conv_7x1_1x7', 2), ('sep_conv_3x3', 0)], normal_concat=[4, 5, 6], reduce=[('dil_conv_5x5', 0), ('avg_pool_3x3', 1), ('max_pool_3x3', 2), ('dil_conv_3x3', 0), ('avg_pool_3x3', 3), ('sep_conv_3x3', 3), ('sep_conv_7x7', 3), ('avg_pool_3x3', 4), ('avg_pool_3x3', 5), ('skip_connect', 4)], reduce_concat=[6])\n",
            "08/08 12:35:00 AM param size = 0.564212MB\n",
            "08/08 12:35:00 AM epoch 0 lr 1.406250e-02\n",
            "08/08 12:37:01 AM train_acc 87.570093\n",
            "08/08 12:37:01 AM epoch 1 lr 2.083333e-03\n",
            "Traceback (most recent call last):\n",
            "  File \"nsga-net/search/evolution_search.py\", line 230, in <module>\n",
            "    main()\n",
            "  File \"nsga-net/search/evolution_search.py\", line 224, in main\n",
            "    termination=('n_gen', args.n_gens))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pymoo/optimize.py\", line 47, in minimize\n",
            "    res = method.solve(problem, termination, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pymoo/model/algorithm.py\", line 106, in solve\n",
            "    pop = self._solve(problem, termination)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pymoo/algorithms/genetic_algorithm.py\", line 83, in _solve\n",
            "    self.pop = self._initialize()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pymoo/algorithms/genetic_algorithm.py\", line 121, in _initialize\n",
            "    self.evaluator.eval(self.problem, pop, algorithm=self)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pymoo/model/evaluator.py\", line 51, in eval\n",
            "    **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pymop/problem.py\", line 188, in evaluate\n",
            "    self._evaluate(X, out, *args, **kwargs)\n",
            "  File \"nsga-net/search/evolution_search.py\", line 154, in _evaluate\n",
            "    val_dataset=val_dataset)\n",
            "  File \"/content/nsga-net/search/train_search.py\", line 153, in main\n",
            "    train_acc, train_obj = train(train_queue, model, criterion, optimizer, train_params)\n",
            "  File \"/content/nsga-net/search/train_search.py\", line 239, in train\n",
            "    nn.utils.clip_grad_norm_(net.parameters(), params['grad_clip'])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/utils/clip_grad.py\", line 33, in clip_grad_norm_\n",
            "    total_norm += param_norm.item() ** norm_type\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0_lHxofJaQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,Y=2,2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prOoE1oUOo38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del X,Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p-xSqtVOqDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "ae7dba54-8761-415b-8634-e61265a9db42"
      },
      "source": [
        "Y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c881daf1af41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2ha6kRAOqv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "f813e9d7-43bf-4e01-9105-0303f4daec46"
      },
      "source": [
        "%cd nsga-net/\n",
        "!git pull https://github.com/DanielDimanov/nsga-net.git\n",
        "%cd /content/"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/nsga-net\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), done.\n",
            "From https://github.com/DanielDimanov/nsga-net\n",
            " * branch            HEAD       -> FETCH_HEAD\n",
            "Updating 62e5511..42c70ac\n",
            "Fast-forward\n",
            " search/evolution_search.py | 1 \u001b[32m+\u001b[m\n",
            " search/train_search.py     | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 2 insertions(+), 1 deletion(-)\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0qitCg6PY7r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f0a7123-43dc-49db-e13c-a5165f9ccd61"
      },
      "source": [
        "%cd nsga-net/"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/nsga-net\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy4AK1yChNbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd516245-1ba1-4f95-aff2-1db1ffd540b5"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2RqTz58iv5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mv -i nsga-net/ /content/gdrive/My\\ Drive/MScProject/nsga-netv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WhABL61jL6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "a7a2557d-03a5-4f89-e233-90f5aaa2aa19"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Usage: mv [OPTION]... [-T] SOURCE DEST\n",
            "  or:  mv [OPTION]... SOURCE... DIRECTORY\n",
            "  or:  mv [OPTION]... -t DIRECTORY SOURCE...\n",
            "Rename SOURCE to DEST, or move SOURCE(s) to DIRECTORY.\n",
            "\n",
            "Mandatory arguments to long options are mandatory for short options too.\n",
            "      --backup[=CONTROL]       make a backup of each existing destination file\n",
            "  -b                           like --backup but does not accept an argument\n",
            "  -f, --force                  do not prompt before overwriting\n",
            "  -i, --interactive            prompt before overwrite\n",
            "  -n, --no-clobber             do not overwrite an existing file\n",
            "If you specify more than one of -i, -f, -n, only the final one takes effect.\n",
            "      --strip-trailing-slashes  remove any trailing slashes from each SOURCE\n",
            "                                 argument\n",
            "  -S, --suffix=SUFFIX          override the usual backup suffix\n",
            "  -t, --target-directory=DIRECTORY  move all SOURCE arguments into DIRECTORY\n",
            "  -T, --no-target-directory    treat DEST as a normal file\n",
            "  -u, --update                 move only when the SOURCE file is newer\n",
            "                                 than the destination file or when the\n",
            "                                 destination file is missing\n",
            "  -v, --verbose                explain what is being done\n",
            "  -Z, --context                set SELinux security context of destination\n",
            "                                 file to default type\n",
            "      --help     display this help and exit\n",
            "      --version  output version information and exit\n",
            "\n",
            "The backup suffix is '~', unless set with --suffix or SIMPLE_BACKUP_SUFFIX.\n",
            "The version control method may be selected via the --backup option or through\n",
            "the VERSION_CONTROL environment variable.  Here are the values:\n",
            "\n",
            "  none, off       never make backups (even if --backup is given)\n",
            "  numbered, t     make numbered backups\n",
            "  existing, nil   numbered if numbered backups exist, simple otherwise\n",
            "  simple, never   always make simple backups\n",
            "\n",
            "GNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n",
            "Full documentation at: <http://www.gnu.org/software/coreutils/mv>\n",
            "or available locally via: info '(coreutils) mv invocation'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iquug6pdjNzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}